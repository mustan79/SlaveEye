import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
import base64

# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="AkÄ±llÄ± Asistan",
    page_icon="ğŸ¤–",
    layout="centered"
)

# CSS yÃ¼kle
with open("style.css") as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

st.title("ğŸ¤– AkÄ±llÄ± Asistan")

# Ã‡evresel deÄŸiÅŸkenleri yÃ¼kle
load_dotenv()
google_api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
if not google_api_key:
    st.error("Google API Key bulunamadÄ±. LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    st.stop()

# Gemini API yapÄ±landÄ±rmasÄ±
genai.configure(api_key=google_api_key)
model = genai.GenerativeModel('gemini-2.5-flash')

# Sesli yanÄ±t fonksiyonu
def speak(text):
    """Metni sesli olarak okuma"""
    speak_html = f"""
    <script>
    var msg = new SpeechSynthesisUtterance({text!r});
    msg.lang = 'tr-TR';
    msg.rate = 1.0;
    window.speechSynthesis.speak(msg);
    </script>"""
    st.components.v1.html(speak_html, height=0)

# Session state baÅŸlatma
if "captured_image" not in st.session_state:
    st.session_state["captured_image"] = None
if "mic_text" not in st.session_state:
    st.session_state["mic_text"] = ""

# Mikrofon HTML komponenti
mic_html = """
<div style="text-align: center; margin: 20px;">
  <button class="big-button" id="start-record" onclick="startMic()">ğŸ¤ Mikrofon</button>
  <div id="mic-result" style="font-weight: bold; font-size: 1.2em; margin-top: 10px; color: #333;"></div>
</div>
<script>
function startMic() {
  const btn = document.getElementById('start-record');
  const result = document.getElementById('mic-result');
  
  if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
    result.innerText = "TarayÄ±cÄ± mikrofon desteÄŸi yok!";
    return;
  }
  
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  const recognition = new SpeechRecognition();
  
  recognition.lang = "tr-TR";
  recognition.continuous = false;
  recognition.interimResults = false;

  recognition.onstart = function() {
    btn.innerText = "ğŸ”Š Dinleniyor...";
    result.innerText = "Mikrofon aktif...";
  };

  recognition.onresult = function(event) {
    const text = event.results[0][0].transcript;
    result.innerText = "AnladÄ±ÄŸÄ±m: " + text;
    
    // Streamlit'e metni gÃ¶nder
    window.parent.postMessage({
      type: "streamlit:setComponentValue",
      data: text
    }, "*");
    
    btn.innerText = "ğŸ¤ Mikrofon";
  };

  recognition.onerror = function(event) {
    result.innerText = "Hata: " + event.error;
    btn.innerText = "ğŸ¤ Mikrofon";
  };

  recognition.onend = function() {
    btn.innerText = "ğŸ¤ Mikrofon";
  };

  recognition.start();
}
</script>
"""

# Mikrofon bileÅŸeni
mic_result = st.components.v1.html(mic_html, height=150)

# Mikrofon verisini session state'e kaydet
if isinstance(mic_result, str) and mic_result.strip():
    st.session_state["mic_text"] = mic_result

# Butonlar iÃ§in CSS
st.markdown("""
<style>
.big-button {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  border: none;
  color: white;
  padding: 20px 40px;
  font-size: 24px;
  border-radius: 15px;
  cursor: pointer;
  transition: all 0.3s ease;
  margin: 10px;
  box-shadow: 0 4px 15px rgba(0,0,0,0.2);
}

.big-button:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(0,0,0,0.3);
}

.button-container {
  display: flex;
  justify-content: center;
  gap: 30px;
  margin: 30px 0;
}

.camera-container {
  text-align: center;
  margin: 20px 0;
}
</style>
""", unsafe_allow_html=True)

# Ana butonlar
col1, col2 = st.columns([1, 1])

with col1:
    # Resim Ã§ek butonu
    camera_photo = st.camera_input(
        "ğŸ“¸ Resim Ã‡ek",
        key="photo_capture",
        help="Bu butona bastÄ±ÄŸÄ±nÄ±zda kamera aktif olacak ve arkaplanda Ã§alÄ±ÅŸacak"
    )
    
    if camera_photo:
        st.session_state["captured_image"] = camera_photo
        if st.session_state["mic_text"]:
            # Mikrofon giriÅŸi varsa onu kullan
            prompt = st.session_state["mic_text"]
            speak("Modelden yanÄ±t bekleniyor...")
        else:
            # Sabit prompt
            prompt = "Bu resimde gÃ¶rdÃ¼klerini detaylÄ± olarak anlat."
            speak("Modelden yanÄ±t bekleniyor...")
        
        # Resmi AI'ya gÃ¶nder
        image = Image.open(st.session_state["captured_image"])
        response = model.generate_content([image, prompt])
        response_text = response.text
        
        # YanÄ±tÄ± seslendir
        speak(response_text)
        
        # Temizle
        st.session_state["mic_text"] = ""

with col2:
    # Mikrofon kullanÄ±m talimatlarÄ±
    st.markdown("### ğŸ¤ Mikrofon KullanÄ±mÄ±:")
    st.markdown("1. Mikrofon butonuna basÄ±n")
    st.markdown("2. Ne istediÄŸinizi sÃ¶yleyin")
    st.markdown("3. Kamera otomatik fotoÄŸraf Ã§ekecek")
    st.markdown("4. Ä°steÄŸinizle ilgili yanÄ±t gelecek")
    
    if st.session_state["mic_text"]:
        st.success(f"Son mikrofon giriÅŸi: **{st.session_state['mic_text']}**")

# Bilgi alanÄ±
st.markdown("---")
st.markdown("ğŸ’¡ **Ä°puÃ§larÄ±:**")
st.markdown("- Resim Ã§ek butonuna bastÄ±ÄŸÄ±nÄ±zda kamera aÃ§Ä±lacak")
st.markdown("- Mikrofon kullanmak iÃ§in Ã¶nce mikrofon butonuna basÄ±n")
st.markdown("- TÃ¼m yanÄ±tlar sesli olarak okunacak")