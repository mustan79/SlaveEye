import streamlit as st
from PIL import Image
import google.generativeai as genai

st.title("ğŸ”Š AkÄ±llÄ± Sesli Asistan")

# API anahtarÄ± Streamlit secrets Ã¼zerinden alÄ±nÄ±r
google_api_key = st.secrets.get("GEMINI_API_KEY")
if not google_api_key:
    st.error("Google API Key bulunamadÄ±. LÃ¼tfen Streamlit secrets'a ekleyin.")
    st.stop()

genai.configure(api_key=google_api_key)
model = genai.GenerativeModel('gemini-2.5-flash')

st.markdown("""
<style>
    .big-btn {width:96vw; height:8vh; font-size:3em; margin:1vh 0;}
</style>
""", unsafe_allow_html=True)

info_area = st.empty()

def speak(text):
    info_area.info(text)
    speak_html = f"""
    <script>
    var msg = new SpeechSynthesisUtterance({text!r});
    msg.lang = 'tr-TR'; window.speechSynthesis.speak(msg);
    </script>"""
    st.components.v1.html(speak_html, height=0)

if "mic_prompt" not in st.session_state:
    st.session_state["mic_prompt"] = None
#if "component_value" not in st.session_state:
#    st.session_state["component_value"] = None # ArtÄ±k gerekli deÄŸil
mic_flag = False # BaÅŸlangÄ±Ã§ta False olmalÄ±

resim = st.camera_input("Kamera ile fotoÄŸraf Ã§ek")

if resim:
    # Resmi PIL Image objesine Ã§evir
    img = Image.open(resim)
    speak("Modelden yanÄ±t bekleniyor...")

    prompt = st.session_state["mic_prompt"] if mic_flag else "Bu resimde neler var?"

    yanit = model.generate_content([img, prompt]).text
    speak(yanit)


# --- Mikrofon akÄ±ÅŸÄ± ---
mic_html = """
<div>
  <button class="big-btn" id="start-record">ğŸ¤ KonuÅŸmaya BaÅŸla</button>
  <p id="mic-result" style="font-weight:bold; font-size:1.5em"></p>
</div>
<script>
const btn = document.getElementById('start-record');
const result = document.getElementById('mic-result');
if ('webkitSpeechRecognition' in window) {
  let recognition = new webkitSpeechRecognition();
  recognition.lang = "tr-TR"; recognition.continuous = false; recognition.interimResults = false;
  btn.onclick = () => { recognition.start(); btn.innerText = "Dinleniyor..."; };
  recognition.onresult = (e) => {
    let text = e.results[0][0].transcript;
    result.innerText = text;
    window.parent.postMessage({isStreamlitMessage: true, type: "streamlit:setComponentValue", data: text}, "*");
    btn.innerText = "ğŸ¤ KonuÅŸmaya BaÅŸla";
  };
  recognition.onerror = (e) => { result.innerText = "Hata: " + e.error; btn.innerText = "ğŸ¤ KonuÅŸmaya BaÅŸla"; };
  recognition.onstart = () => {
    // Mikrofon baÅŸladÄ±ÄŸÄ±nda flag'i Streamlit'e gÃ¶nder
    window.parent.postMessage({isStreamlitMessage: true, type: "streamlit:setComponentValue", data: 'mic_started'}, "*");
  }
else {
  result.innerText = "TarayÄ±cÄ± mikrofon desteÄŸi yok!";
  btn.disabled = false;
}
</script>
"""
st.components.v1.html(mic_html, height=230)

# `streamlit:setComponentValue` mesajÄ±nÄ± yakala
mic_data = st.session_state.get("component_value")

if mic_data == 'mic_started':
    # Sadece mikrofon baÅŸladÄ±ysa flag'i ayarla
    mic_flag = True

elif mic_data:
    # Mikrofon verisi geldiyse hem prompt'u ayarla, hem de flag'i true yap
    st.session_state["mic_prompt"] = mic_data
    mic_flag = True
```

**DeÄŸiÅŸikliklerin AÃ§Ä±klamasÄ±:**

*   **`mic_flag` BaÅŸlangÄ±Ã§ DeÄŸeri:** `mic_flag = False` olarak ayarlandÄ±. Program ilk baÅŸladÄ±ÄŸÄ±nda mikrofonun kullanÄ±lmadÄ±ÄŸÄ±nÄ± belirtmek iÃ§in bu Ã¶nemlidir.
*   **`mic_flag` DoÄŸru KullanÄ±mÄ±:**
    *   `if mic_flag == 1;` yerine `if mic_flag:` kullanÄ±ldÄ±. Python'da boolean deÄŸerleri doÄŸrudan kontrol etmek daha yaygÄ±ndÄ±r.
    *   `else;` silindi. Python'da `else` ifadesi `if` bloÄŸunun hemen altÄ±nda olmalÄ±dÄ±r.
*   **`st.session_state` TemizliÄŸi:**
    *   `st.session_state["step"]` ve  `st.session_state["component_value"]`  deÄŸiÅŸkenlerine artÄ±k gerek kalmadÄ±ÄŸÄ± iÃ§in kaldÄ±rÄ±ldÄ±.
*   **Prompt SeÃ§imi:** Prompt seÃ§imi daha anlaÅŸÄ±lÄ±r hale getirildi:

    ```python
    prompt = st.session_state["mic_prompt"] if mic_flag else "Bu resimde neler var?"
