import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image

st.set_page_config(page_title="AkÄ±llÄ± Sesli Asistan", layout="wide")

# --- CSS: ButonlarÄ± bÃ¼yÃ¼t, kamera inputunu gizle ---
st.markdown("""
<style>
.big-btn {width:96vw; height:8vh; font-size:3em; margin:1vh 0;}
[data-testid="stCameraInput"] {display: none !important;}
</style>
""", unsafe_allow_html=True)

st.title("ğŸ”Š AkÄ±llÄ± Sesli Asistan")

load_dotenv()
google_api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
if not google_api_key:
    st.error("Google API Key bulunamadÄ±. LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    st.stop()

genai.configure(api_key=google_api_key)
model = genai.GenerativeModel('gemini-1.5-flash-latest')

info_area = st.empty()

if "cekilen_resim" not in st.session_state:
    st.session_state["cekilen_resim"] = None
if "mic_prompt" not in st.session_state:
    st.session_state["mic_prompt"] = None
if "mic_waiting_photo" not in st.session_state:
    st.session_state["mic_waiting_photo"] = False
if "mic_listen" not in st.session_state:
    st.session_state["mic_listen"] = False

# --- SADE EKRAN: 2 BUTON ---
col1, col2 = st.columns(2)
with col1:
    foto_btn = st.button("ğŸ“· Resim Ã‡ek", key="btn_foto", use_container_width=True)
with col2:
    mic_btn = st.button("ğŸ¤ Mikrofon", key="btn_mic", use_container_width=True)

# --- KAMERA INPUTU (gizli) ---
camera_file = st.camera_input("", key="cam_input", label_visibility="collapsed")

# --- 1. MOD: SADECE RESÄ°M Ã‡EK ---
if foto_btn:
    info_area.info("Kamera aÃ§Ä±lÄ±yor... Bir fotoÄŸraf Ã§ekin.")
    # Bilgilendirmeyi seslendir
    st.components.v1.html("""
    <script>
    var msg = new SpeechSynthesisUtterance("Kamera aÃ§Ä±lÄ±yor, lÃ¼tfen bir fotoÄŸraf Ã§ekin.");
    msg.lang = 'tr-TR'; window.speechSynthesis.speak(msg);
    </script>
    """, height=0)
    st.stop()  # Yeniden yÃ¼klemede camera_input aÃ§Ä±lÄ±r

if camera_file and not st.session_state.get("mic_waiting_photo"):
    try:
        img = Image.open(camera_file)
        prompt = "Bu resimde neler gÃ¶rÃ¼yorsun?"
        info_area.info("ğŸŸ¢ Modelden yanÄ±t bekleniyor...")
        yanit = model.generate_content([img, prompt]).text
        info_area.success("âœ… YanÄ±t seslendiriliyor...")
        st.components.v1.html(f"""
        <script>
        var msg = new SpeechSynthesisUtterance({yanit!r});
        msg.lang = 'tr-TR'; window.speechSynthesis.speak(msg);
        </script>
        """, height=0)
    except Exception as e:
        info_area.error(f"Hata: {e}")
        st.components.v1.html(f"""
        <script>
        var msg = new SpeechSynthesisUtterance("Hata oluÅŸtu: {str(e)}");
        msg.lang = 'tr-TR'; window.speechSynthesis.speak(msg);
        </script>
        """, height=0)

# --- 2. MOD: MÄ°KROFON Ä°LE PROMPT AL, SONRA FOTOÄRAF Ã‡EK ---
if mic_btn:
    st.session_state["mic_listen"] = True

if st.session_state.get("mic_listen"):
    mic_html = """
    <div>
      <button class="big-btn" id="start-record">ğŸ¤ KonuÅŸmaya BaÅŸla</button>
      <p id="mic-result" style="font-weight:bold; font-size:1.5em"></p>
    </div>
    <script>
    const btn = document.getElementById('start-record');
    const result = document.getElementById('mic-result');
    if ('webkitSpeechRecognition' in window) {
      let recognition = new webkitSpeechRecognition();
      recognition.lang = "tr-TR"; recognition.continuous = false; recognition.interimResults = false;
      btn.onclick = () => { recognition.start(); btn.innerText = "Dinleniyor..."; };
      recognition.onresult = (e) => {
        let text = e.results[0][0].transcript;
        result.innerText = text;
        window.parent.postMessage({isStreamlitMessage: true, type: "streamlit:setComponentValue", data: text}, "*");
        btn.innerText = "ğŸ¤ KonuÅŸmaya BaÅŸla";
      };
      recognition.onerror = (e) => { result.innerText = "Hata: " + e.error; btn.innerText = "ğŸ¤ KonuÅŸmaya BaÅŸla"; };
    } else {
      result.innerText = "TarayÄ±cÄ± mikrofon desteÄŸi yok!";
      btn.disabled = true;
    }
    </script>
    """
    mic_text = st.components.v1.html(mic_html, height=230)
    val = st.session_state.get("component_value")
    if val:
        st.session_state["mic_prompt"] = val
        st.session_state["mic_listen"] = False
        st.session_state["mic_waiting_photo"] = True
        info_area.info("Åimdi fotoÄŸraf Ã§ekin lÃ¼tfen!")
        st.components.v1.html("""
        <script>
        var msg = new SpeechSynthesisUtterance("Åimdi fotoÄŸraf Ã§ekin lÃ¼tfen!");
        msg.lang = 'tr-TR'; window.speechSynthesis.speak(msg);
        </script>
        """, height=0)
        st.stop()

if camera_file and st.session_state.get("mic_waiting_photo"):
    try:
        img = Image.open(camera_file)
        prompt = st.session_state["mic_prompt"] or "Bu resimde neler var?"
        yanit = model.generate_content([img, prompt]).text
        info_area.success("âœ… YanÄ±t seslendiriliyor...")
        st.components.v1.html(f"""
        <script>
        var msg = new SpeechSynthesisUtterance({yanit!r});
        msg.lang = 'tr-TR'; window.speechSynthesis.speak(msg);
        </script>
        """, height=0)
        st.session_state["mic_prompt"] = None
        st.session_state["mic_waiting_photo"] = False
    except Exception as e:
        info_area.error(f"Hata: {e}")
        st.components.v1.html(f"""
        <script>
        var msg = new SpeechSynthesisUtterance("Hata oluÅŸtu: {str(e)}");
        msg.lang = 'tr-TR'; window.speechSynthesis.speak(msg);
        </script>
        """, height=0)
        st.session_state["mic_prompt"] = None
        st.session_state["mic_waiting_photo"] = False

st.info("""
**KullanÄ±m:**
- ğŸ“· Resim Ã‡ek: Sadece fotoÄŸraf Ã§ekip, modelden yanÄ±tÄ± sesli alÄ±rsÄ±nÄ±z.
- ğŸ¤ Mikrofon: Ã–nce konuÅŸarak prompt girersiniz, hemen ardÄ±ndan fotoÄŸraf Ã§ekersiniz. Ä°kisi birlikte modele gider, yanÄ±t sesli dÃ¶ner.
- Kamera ve fotoÄŸraf hiÃ§bir zaman ekranda gÃ¶sterilmez.
""")

