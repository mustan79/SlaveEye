import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image

# --- CSS: ButonlarÄ± bÃ¼yÃ¼k yap, kamera inputunu gizle ---
st.markdown("""
<style>
    .big-btn {width:96vw; height:8vh; font-size:3em; margin:1vh 0;}
    [data-testid="stCameraInput"] {display: none !important;}
</style>
""", unsafe_allow_html=True)

st.title("ğŸ”Š AkÄ±llÄ± Sesli Asistan")

# --- API Key YÃ¼kle ---
load_dotenv()
google_api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
if not google_api_key:
    st.error("Google API Key bulunamadÄ±. LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    st.stop()

genai.configure(api_key=google_api_key)
model = genai.GenerativeModel('gemini-1.5-flash-latest')

info_area = st.empty()

# --- Session State BaÅŸlat ---
for k, v in [
    ("cekilen_resim", None),
    ("mic_prompt", None),
    ("step", None),
    ("mic_listen", False),
    ("mic_value", None)
]:
    if k not in st.session_state:
        st.session_state[k] = v

# --- Ana Butonlar ---
col1, col2 = st.columns(2)
with col1:
    foto_btn = st.button("ğŸ“· Resim Ã‡ek", key="btn_foto", use_container_width=True)
with col2:
    mic_btn = st.button("ğŸ¤ Mikrofonla Sor", key="btn_mic", use_container_width=True)

# --- Kamera Inputu (her zaman hazÄ±r, gizli) ---
camera_file = st.camera_input("", key="cam_input", label_visibility="collapsed")

def speak(text):
    # Ekranda gÃ¶ster + sesli okut
    info_area.info(text)
    speak_html = f"""
    <script>
    var msg = new SpeechSynthesisUtterance({text!r});
    msg.lang = 'tr-TR'; window.speechSynthesis.speak(msg);
    </script>"""
    st.components.v1.html(speak_html, height=0)

# --- FOTOÄRAF Ã‡EKME AKIÅI ---
if foto_btn:
    st.session_state["step"] = "foto"
    speak("Kamera aÃ§Ä±lÄ±yor, lÃ¼tfen fotoÄŸraf Ã§ekin ve yÃ¼kleyin.")
    st.stop()

if st.session_state["step"] == "foto" and camera_file:
    try:
        img = Image.open(camera_file)
        st.session_state["cekilen_resim"] = img
        speak("ğŸŸ¢ Modelden yanÄ±t bekleniyor...")
        yanit = model.generate_content([img, "Bu resimde neler var?"]).text
        speak("âœ… YanÄ±t seslendiriliyor...")
        speak(yanit)
        st.session_state["step"] = None
    except Exception as e:
        speak(f"Hata: {e}")
        st.session_state["step"] = None

# --- MÄ°KROFON AKIÅI ---
if mic_btn:
    st.session_state["step"] = "mic"
    st.session_state["mic_listen"] = True

if st.session_state.get("mic_listen"):
    mic_html = """
    <div>
      <button class="big-btn" id="start-record">ğŸ¤ KonuÅŸmaya BaÅŸla</button>
      <p id="mic-result" style="font-weight:bold; font-size:1.5em"></p>
    </div>
    <script>
    const btn = document.getElementById('start-record');
    const result = document.getElementById('mic-result');
    if ('webkitSpeechRecognition' in window) {
      let recognition = new webkitSpeechRecognition();
      recognition.lang = "tr-TR"; recognition.continuous = false; recognition.interimResults = false;
      btn.onclick = () => { recognition.start(); btn.innerText = "Dinleniyor..."; };
      recognition.onresult = (e) => {
        let text = e.results[0][0].transcript;
        result.innerText = text;
        window.parent.postMessage({isStreamlitMessage: true, type: "streamlit:setComponentValue", data: text}, "*");
        btn.innerText = "ğŸ¤ KonuÅŸmaya BaÅŸla";
      };
      recognition.onerror = (e) => { result.innerText = "Hata: " + e.error; btn.innerText = "ğŸ¤ KonuÅŸmaya BaÅŸla"; };
    } else {
      result.innerText = "TarayÄ±cÄ± mikrofon desteÄŸi yok!";
      btn.disabled = true;
    }
    </script>
    """
    st.components.v1.html(mic_html, height=230)
    mic_value = st.session_state.get("component_value")
    if mic_value:
        st.session_state["mic_prompt"] = mic_value
        st.session_state["mic_listen"] = False
        st.session_state["step"] = "mic_photo"
        speak("Åimdi fotoÄŸraf Ã§ekmeniz gerekiyor. Kamera aÃ§Ä±lÄ±yor.")
        st.stop()

# --- MÄ°KROFON SONRASI FOTOÄRAF AKIÅI ---
if st.session_state["step"] == "mic_photo" and camera_file:
    try:
        img = Image.open(camera_file)
        st.session_state["cekilen_resim"] = img
        prompt = st.session_state["mic_prompt"] or "Bu resimde neler var?"
        speak("ğŸŸ¢ Modelden yanÄ±t bekleniyor...")
        yanit = model.generate_content([img, prompt]).text
        speak("âœ… YanÄ±t seslendiriliyor...")
        speak(yanit)
        st.session_state["mic_prompt"] = None
        st.session_state["step"] = None
    except Exception as e:
        speak(f"Hata: {e}")
        st.session_state["step"] = None

st.info("""
- ğŸ“· **Resim Ã‡ek:** Kameradan fotoÄŸraf Ã§ek, model yanÄ±tÄ±nÄ± otomatik seslendirir.
- ğŸ¤ **Mikrofonla Sor:** KonuÅŸ, ardÄ±ndan fotoÄŸraf Ã§ekmeni ister, ikisini birlikte modele yollar ve yanÄ±tÄ± seslendirir.
""")

