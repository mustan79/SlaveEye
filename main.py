import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
import io

# CSS yÃ¼kle
with open("style.css") as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

st.title("ğŸ“¸ AkÄ±llÄ± Asistan (TarayÄ±cÄ±da Sesli)")

# Ã‡evresel deÄŸiÅŸkenleri yÃ¼kle
load_dotenv()
google_api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
if not google_api_key:
    st.error("Google API Key bulunamadÄ±. LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    st.stop()

# Gemini API yapÄ±landÄ±rmasÄ±
genai.configure(api_key=google_api_key)
model = genai.GenerativeModel('gemini-2.5-flash')

# Global deÄŸiÅŸkenler
son_cekilen_resim = None
info_area = st.empty()

def speak(text):
    info_area.info(text)
    speak_html = f"""
    <script>
    var msg = new SpeechSynthesisUtterance({text!r});
    msg.lang = 'tr-TR'; window.speechSynthesis.speak(msg);
    </script>"""
    st.components.v1.html(speak_html, height=0)

if "mic_prompt" not in st.session_state:
    st.session_state["mic_prompt"] = None
mic_flag = False # BaÅŸlangÄ±Ã§ta False olmalÄ±

# ======= TARAYICI MÄ°KROFON - SES TO TEXT =======
mic_html = """
<div>
  <button class="big-button" id="start-record">ğŸ¤ Mikrofondan KonuÅŸ</button>
  <p id="mic-result" style="font-weight:bold; font-size:1.2em"></p>
</div>
<script>
  const btn = document.getElementById('start-record');
  const result = document.getElementById('mic-result');
  let recognition;
  if ('webkitSpeechRecognition' in window) {
    recognition = new webkitSpeechRecognition();
    recognition.lang = "tr-TR";
    recognition.continuous = false;
    recognition.interimResults = false;

    btn.onclick = () => {
      recognition.start();
      btn.innerText = "Dinleniyor...";
    };

    recognition.onresult = (e) => {
      let text = e.results[0][0].transcript;
      result.innerText = text;
      // Streamlit yazÄ±lÄ± inputa otomatik aktarÄ±m iÃ§in:
      window.parent.postMessage({isStreamlitMessage: true, type: "streamlit:setComponentValue", data: text}, "*");
      btn.innerText = "ğŸ¤ Mikrofondan KonuÅŸ";
    };

    recognition.onerror = (e) => {
      result.innerText = "Hata: " + e.error;
      btn.innerText = "ğŸ¤ Mikrofondan KonuÅŸ";
    };
  } else {
    result.innerText = "TarayÄ±cÄ± mikrofon desteÄŸi yok!";
    btn.disabled = true;
  }
</script>
"""

mic_text = st.components.v1.html(mic_html, height=200)

if mic_data == 'mic_started':
    # Sadece mikrofon baÅŸladÄ±ysa flag'i ayarla
    mic_flag = True

elif mic_data:
    # Mikrofon verisi geldiyse hem prompt'u ayarla, hem de flag'i true yap
    st.session_state["mic_prompt"] = mic_data
    mic_flag = True


# ======= UI =======
# Kamera seÃ§imi (Mobil iÃ§in)
kamera_secimi = st.radio("Kamera SeÃ§imi:", ("Arka Kamera", "Ã–n Kamera"))

# Resim Ã§ekme butonu
captured_image = st.camera_input("2. Resim Ã‡ek",key="kalici_resim")
if captured_image:
    son_cekilen_resim = Image.open(captured_image)
    st.image(captured_image, caption="Ã‡ekilen Resim", use_column_width=True)
#    prompt = "Bu resimde neler gÃ¶rÃ¼yorsun anlat."
    speak("Modelden yanÄ±t bekleniyor...")
    prompt = st.session_state["mic_prompt"] if mic_flag else "Bu resimde neler var?"
    yanit = model.generate_content([img, prompt]).text
    speak(yanit)


col1, col2 = st.columns([2,1])
with col1:
    st.markdown("Mikrofondan aldÄ±ÄŸÄ±nÄ±z metin otomatik buraya gelir.")

